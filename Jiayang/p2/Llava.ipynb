{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5eb0c25-b24f-4ab8-bbdf-8fac071c10e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbdee16446e54233933ba72248591ebc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoProcessor, AutoModelForImageTextToText\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\"llava-hf/llava-1.5-7b-hf\")\n",
    "model = AutoModelForImageTextToText.from_pretrained(\"llava-hf/llava-1.5-7b-hf\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e40b2f-b86a-417f-af12-b0b2a6612990",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b48696aa-a22b-4fdd-b849-4cbcaf90fed7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c70982962614f508e8efb262db771a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Expanding inputs for image tokens in LLaVa should be done in processing. Please add `patch_size` and `vision_feature_select_strategy` to the model's processing config or set directly with `processor.patch_size = {{patch_size}}` and processor.vision_feature_select_strategy = {{vision_feature_select_strategy}}`. Using processors without these attributes in the config is deprecated and will throw an error in v4.47.\n",
      "Expanding inputs for image tokens in LLaVa should be done in processing. Please add `patch_size` and `vision_feature_select_strategy` to the model's processing config or set directly with `processor.patch_size = {{patch_size}}` and processor.vision_feature_select_strategy = {{vision_feature_select_strategy}}`. Using processors without these attributes in the config is deprecated and will throw an error in v4.47.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Output: ER:  \n",
      "What are these? ASSISTANT: These\n",
      "\n",
      "Logits for each token in the output:\n",
      "Token: <s>, Logit: 0.70751953125\n",
      "Token: ▁US, Logit: -0.1290283203125\n",
      "Token: ER, Logit: 4.140625\n",
      "Token: :, Logit: 2.908203125\n",
      "Token: ▁, Logit: 4.09375\n",
      "Token: <image>, Logit: 0.2261962890625\n",
      "Token: ▁, Logit: 7.23046875\n",
      "Token: <0x0A>, Logit: 9.734375\n",
      "Token: What, Logit: 5.03515625\n",
      "Token: ▁are, Logit: 6.69921875\n",
      "Token: ▁these, Logit: 6.8828125\n",
      "Token: ?, Logit: 4.53125\n",
      "Token: ▁A, Logit: 6.92578125\n",
      "Token: SS, Logit: 0.43212890625\n",
      "Token: IST, Logit: -0.95751953125\n",
      "Token: ANT, Logit: -1.0126953125\n",
      "Token: :, Logit: 8.71875\n",
      "Token: ▁These, Logit: 4.5859375\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from PIL import Image\n",
    "import torch\n",
    "from transformers import AutoProcessor, LlavaForConditionalGeneration\n",
    "\n",
    "# Load the model and processor\n",
    "model_id = \"llava-hf/llava-1.5-7b-hf\"\n",
    "model = LlavaForConditionalGeneration.from_pretrained(\n",
    "    model_id, \n",
    "    torch_dtype=torch.float16, \n",
    "    low_cpu_mem_usage=True, \n",
    ").to(0)\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "\n",
    "# Define a chat history and use `apply_chat_template` to get correctly formatted prompt\n",
    "conversation = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"text\", \"text\": \"What are these?\"},\n",
    "            {\"type\": \"image\"},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "prompt = processor.apply_chat_template(conversation, add_generation_prompt=True)\n",
    "\n",
    "# Load and preprocess the image\n",
    "image_file = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n",
    "raw_image = Image.open(requests.get(image_file, stream=True).raw)\n",
    "inputs = processor(images=raw_image, text=prompt, return_tensors='pt').to(0, torch.float16)\n",
    "\n",
    "# Forward pass to get logits\n",
    "with torch.no_grad():\n",
    "    output = model(**inputs)\n",
    "    logits = output.logits  # Shape: (batch_size, sequence_length, vocab_size)\n",
    "\n",
    "# Generate the output tokens using model.generate\n",
    "generated_ids = model.generate(**inputs, max_new_tokens=1, do_sample=False)\n",
    "\n",
    "# Decode the generated tokens to get the actual output\n",
    "output_text = processor.decode(generated_ids[0][2:], skip_special_tokens=True)\n",
    "print(\"Model Output:\", output_text)\n",
    "\n",
    "# Extract logits for the generated tokens\n",
    "# Here we take logits only for the generated tokens\n",
    "token_logits = []\n",
    "for i, token_id in enumerate(generated_ids[0]):\n",
    "    token_logits.append(logits[0, i, token_id].item())\n",
    "\n",
    "# Print logits for each generated token\n",
    "print(\"\\nLogits for each token in the output:\")\n",
    "for token, logit in zip(processor.tokenizer.convert_ids_to_tokens(generated_ids[0]), token_logits):\n",
    "    print(f\"Token: {token}, Logit: {logit}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f10dd50-be16-4fe3-8919-46a3bb2d114d",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d33ff2-e136-4cad-9dda-c2c3e9284f46",
   "metadata": {},
   "source": [
    "## Load AOKVQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53820a04-f01f-40ab-aaf0-a944c99de240",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "aokvqa_dir = \"aokvqa/datasets/aokvqa\"\n",
    "coco_dir = \"aokvqa/datasets/coco\"\n",
    "\n",
    "aokvqa_dataset = json.load(open(\n",
    "        os.path.join(aokvqa_dir, f\"aokvqa_v1p0_val.json\")\n",
    "))\n",
    "\n",
    "def get_coco_path(split, image_id, coco_dir):\n",
    "    return os.path.join(coco_dir, f\"{split}2017\", f\"{image_id:012}.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82bf0e37-b2aa-4dd0-aa48-449a44f61e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22jbM6gDxdaMaunuzgrsBB\n",
      "aokvqa/datasets/coco/val2017/000000461751.jpg\n",
      "What is in the motorcyclist's mouth?\n",
      "['toothpick', 'food', 'popsicle stick', 'cigarette']\n",
      "He's smoking while riding.\n"
     ]
    }
   ],
   "source": [
    "dataset_example = aokvqa_dataset[0]\n",
    "\n",
    "print(dataset_example['question_id'])\n",
    "# 22MexNkBPpdZGX6sxbxVBH\n",
    "\n",
    "image_path = get_coco_path('val', dataset_example['image_id'], coco_dir)\n",
    "print(image_path)\n",
    "# ./datasets/coco/train2017/000000299207.jpg\n",
    "\n",
    "print(dataset_example['question'])\n",
    "print(dataset_example['choices'])\n",
    "# What is the man by the bags awaiting?\n",
    "# ['skateboarder', 'train', 'delivery', 'cab']\n",
    "\n",
    "correct_choice = dataset_example['choices'][dataset_example['correct_choice_idx'] ]\n",
    "# Corrrect: cab\n",
    "\n",
    "print(dataset_example['rationales'][0])\n",
    "# A train would not be on the street, he would not have luggage waiting for a delivery, and the skateboarder is there and not paying attention to him so a cab is the only possible answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8185e39d-cdae-475d-a099-75642a633627",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'split': 'val',\n",
       " 'image_id': 461751,\n",
       " 'question_id': '22jbM6gDxdaMaunuzgrsBB',\n",
       " 'question': \"What is in the motorcyclist's mouth?\",\n",
       " 'choices': ['toothpick', 'food', 'popsicle stick', 'cigarette'],\n",
       " 'correct_choice_idx': 3,\n",
       " 'direct_answers': ['cigarette',\n",
       "  'cigarette',\n",
       "  'cigarette',\n",
       "  'cigarette',\n",
       "  'cigarette',\n",
       "  'cigarette',\n",
       "  'cigarette',\n",
       "  'cigarette',\n",
       "  'cigarette',\n",
       "  'cigarette'],\n",
       " 'difficult_direct_answer': False,\n",
       " 'rationales': [\"He's smoking while riding.\",\n",
       "  'The motorcyclist has a lit cigarette in his mouth while he rides on the street.',\n",
       "  'The man is smoking.']}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6495218a-0d5f-4cd0-801a-4d561d0ca4af",
   "metadata": {},
   "source": [
    "## Test loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7da3819-bcbe-40de-82ba-d21b9c4f6aa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c38dd78dc824fb0a3902f0d9a8564d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import requests\n",
    "from PIL import Image\n",
    "import torch\n",
    "from transformers import AutoProcessor, LlavaForConditionalGeneration\n",
    "\n",
    "# Load the model and processor\n",
    "model_id = \"llava-hf/llava-1.5-7b-hf\"\n",
    "model = LlavaForConditionalGeneration.from_pretrained(\n",
    "    model_id, \n",
    "    torch_dtype=torch.float16, \n",
    "    low_cpu_mem_usage=True, \n",
    ").to(0)\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13f972cf-30ed-48b9-9417-873a988609ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What is in the motorcyclist's mouth?\n",
      "Choice: 0.toothpick 1.food 2.popsicle stick 3.cigarette\n",
      "Answer:  ASSISTANT: 3\n",
      "3\n",
      "3\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: Which number birthday is probably being celebrated?\n",
      "Choice: 0.one 1.ten 2.nine 3.thirty\n",
      "Answer:  ASSISTANT: 3\n",
      "3\n",
      "3\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What best describes the pool of water?\n",
      "Choice: 0.frozen 1.fresh 2.dirty 3.boiling\n",
      "Answer:  ASSISTANT: 3\n",
      "3\n",
      "2\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What is the white substance on top of the cupcakes?\n",
      "Choice: 0.butter 1.mayo 2.ice cream 3.icing\n",
      "Answer:  ASSISTANT: 3\n",
      "3\n",
      "3\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What type of device is sitting next to the laptop?\n",
      "Choice: 0.mouse 1.mobile phone 2.pen 3.keyboard\n",
      "Answer:  ASSISTANT: 1\n",
      "1\n",
      "1\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: The thing on the animal to the left's head is similar to what is on the head of what else?\n",
      "Choice: 0.devil 1.zombie 2.vampire 3.witch\n",
      "Answer:  ASSISTANT: 3\n",
      "3\n",
      "0\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What is the appliance the woman is holding used for?\n",
      "Choice: 0.cutting hair 1.brushing teeth 2.drying hair 3.painting nails\n",
      "Answer:  ASSISTANT: 2\n",
      "2\n",
      "2\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What is the descriptive word for this surface?\n",
      "Choice: 0.barren 1.crowded 2.minimalist 3.empty\n",
      "Answer:  ASSISTANT: 3\n",
      "3\n",
      "1\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What is the person on the left doing with their body?\n",
      "Choice: 0.crouching 1.leaping 2.flying 3.twirling\n",
      "Answer:  ASSISTANT: 1\n",
      "1\n",
      "0\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What type of pants is the man on the right wearing?\n",
      "Choice: 0.linen 1.corduroy 2.silk 3.denim\n",
      "Answer:  ASSISTANT: 3\n",
      "3\n",
      "3\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What country do these planes belong to?\n",
      "Choice: 0.united states 1.germany 2.canada 3.mexico\n",
      "Answer:  ASSISTANT: 0\n",
      "0\n",
      "0\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What interests the child most here?\n",
      "Choice: 0.table 1.fork 2.candle 3.floor\n",
      "Answer:  ASSISTANT: 2\n",
      "2\n",
      "2\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What kind of fruit is cut in half and darker than the other?\n",
      "Choice: 0.grapes 1.apples 2.lettuce 3.radish\n",
      "Answer:  ASSISTANT: 3\n",
      "3\n",
      "0\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What item on the desk could help with a cold?\n",
      "Choice: 0.cough drops 1.syringe 2.pills 3.herbal tea\n",
      "Answer:  ASSISTANT: 2\n",
      "2\n",
      "0\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What flag is represented on the wall?\n",
      "Choice: 0.english 1.moravian 2.american 3.french\n",
      "Answer:  ASSISTANT: 2\n",
      "2\n",
      "2\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What is located on the shelves?\n",
      "Choice: 0.books 1.dvds 2.games 3.food\n",
      "Answer:  ASSISTANT: 0\n",
      "0\n",
      "0\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What period of the day does this photo reflect?\n",
      "Choice: 0.noon 1.morning 2.dawn 3.afternoon\n",
      "Answer:  ASSISTANT: 3\n",
      "3\n",
      "3\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What activity does the cat appear most likely to do?\n",
      "Choice: 0.drink 1.jump 2.eat 3.sleep\n",
      "Answer:  ASSISTANT: 2\n",
      "2\n",
      "1\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What event is this most likely?\n",
      "Choice: 0.environmental cleanup 1.concert 2.date 3.firing\n",
      "Answer:  ASSISTANT: 2\n",
      "2\n",
      "2\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What is the outside of the cake made of?\n",
      "Choice: 0.frosting 1.custard 2.fondant 3.whipped cream\n",
      "Answer:  ASSISTANT: 2\n",
      "2\n",
      "2\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: Why is the person wearing a white jacket?\n",
      "Choice: 0.nurse 1.doctor 2.cold 3.chef\n",
      "Answer:  ASSISTANT: 3\n",
      "3\n",
      "3\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What is the dog trying to catch?\n",
      "Choice: 0.person 1.frisbee 2.kite 3.ball\n",
      "Answer:  ASSISTANT: 1\n",
      "1\n",
      "1\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: Which animal usually occupies the position the cat is in right now?\n",
      "Choice: 0.human 1.dinosaur 2.eagle 3.fish\n",
      "Answer:  ASSISTANT: 3\n",
      "3\n",
      "0\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What kind of resort are these people at?\n",
      "Choice: 0.swim resort 1.safari 2.ski resort 3.tropical resort\n",
      "Answer:  ASSISTANT: 2\n",
      "2\n",
      "2\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What type of transportation is this?\n",
      "Choice: 0.air 1.water 2.road 3.road\n",
      "Answer:  ASSISTANT: 0\n",
      "0\n",
      "0\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: The cat is looking in what direction?\n",
      "Choice: 0.left 1.right 2.down 3.up\n",
      "Answer:  ASSISTANT: 3\n",
      "3\n",
      "2\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What are the orange vehicles for?\n",
      "Choice: 0.police 1.shuttle 2.passengers 3.air traffic\n",
      "Answer:  ASSISTANT: 3\n",
      "3\n",
      "3\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: The company producing the device in her hand is from what country?\n",
      "Choice: 0.usa 1.china 2.japan 3.spain\n",
      "Answer:  ASSISTANT: 3\n",
      "3\n",
      "2\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: Which is not an ingredient of this dish?\n",
      "Choice: 0.flatbread 1.prosciutto 2.arugula 3.pepperoni\n",
      "Answer:  ASSISTANT: 3\n",
      "3\n",
      "3\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What is closest to the tree trunk?\n",
      "Choice: 0.closed doors 1.walking person 2.sitting person 3.open doors\n",
      "Answer:  ASSISTANT: 3\n",
      "3\n",
      "0\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: Where are we at?\n",
      "Choice: 0.fair 1.garage sale 2.street festival 3.flea market\n",
      "Answer:  ASSISTANT: 2\n",
      "2\n",
      "2\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What is beside the person on the seat?\n",
      "Choice: 0.white bag 1.food 2.paper bag 3.pillow\n",
      "Answer:  ASSISTANT: 2\n",
      "2\n",
      "0\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What does it say on the boys hat?\n",
      "Choice: 0.happy birthday 1.huggy buggy 2.herpy derpy 3.huggy harry\n",
      "Answer:  ASSISTANT: 0\n",
      "0\n",
      "0\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What sport are they mimicking?\n",
      "Choice: 0.baseball 1.lacrosse 2.cricket 3.basketball\n",
      "Answer:  ASSISTANT: 3\n",
      "3\n",
      "0\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: The visible bottles most likely contain what kind of items?\n",
      "Choice: 0.body wash 1.shampoo conditioner 2.lotions 3.mouthwash\n",
      "Answer:  ASSISTANT: 2\n",
      "2\n",
      "1\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What sport game is the man playing?\n",
      "Choice: 0.wii boxing 1.wii baseball 2.wii football 3.wii tennis\n",
      "Answer:  ASSISTANT: 0\n",
      "0\n",
      "0\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What is the batter most likely preparing to do here?\n",
      "Choice: 0.bunt 1.sit 2.dodge ball 3.slide\n",
      "Answer:  ASSISTANT: 3\n",
      "3\n",
      "0\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What kind of venue is it?\n",
      "Choice: 0.garage 1.commercial kitchen 2.auto shop 3.domestic kitchen\n",
      "Answer:  ASSISTANT: 1\n",
      "1\n",
      "3\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What kind of terrain is it?\n",
      "Choice: 0.beach 1.desert 2.savanna 3.valley\n",
      "Answer:  ASSISTANT: 2\n",
      "2\n",
      "2\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What is the bin on the left made from?\n",
      "Choice: 0.plastic 1.ceramic 2.steel 3.glass\n",
      "Answer:  ASSISTANT: 2\n",
      "2\n",
      "2\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What type of animal is on a leash on the sidewalk?\n",
      "Choice: 0.dog 1.tiger 2.cat 3.lion\n",
      "Answer:  ASSISTANT: 3\n",
      "3\n",
      "0\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What room of the house is this man in?\n",
      "Choice: 0.sitting room 1.dinning room 2.bathroom 3.bedroom\n",
      "Answer:  ASSISTANT: 2\n",
      "2\n",
      "2\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What is likely in front of the rug?\n",
      "Choice: 0.refrigerator 1.pantry 2.washing machine 3.sink\n",
      "Answer:  ASSISTANT: 3\n",
      "3\n",
      "3\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: Which food item is the knife for?\n",
      "Choice: 0.bread 1.fruit 2.vegetables 3.meat\n",
      "Answer:  ASSISTANT: 2\n",
      "2\n",
      "3\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What is the orange container on the left near the man in the red shirt used for?\n",
      "Choice: 0.training 1.keeping score 2.batting 3.storage\n",
      "Answer:  ASSISTANT: 2\n",
      "2\n",
      "3\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What type of design is the person's shirt?\n",
      "Choice: 0.striped 1.plaid 2.uniform 3.tie dyed\n",
      "Answer:  ASSISTANT: 3\n",
      "3\n",
      "3\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What kind of cuisine is this?\n",
      "Choice: 0.asian 1.american 2.african 3.european\n",
      "Answer:  ASSISTANT: 0\n",
      "0\n",
      "0\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What is on the side of the yellow plane?\n",
      "Choice: 0.phone number 1.call letters 2.company name 3.decoration\n",
      "Answer:  ASSISTANT: 3\n",
      "3\n",
      "1\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: Why are the men's vests orange?\n",
      "Choice: 0.fashion 1.camouflage 2.visibility 3.dress code\n",
      "Answer:  ASSISTANT: 2\n",
      "2\n",
      "2\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: Why would you sit at this table?\n",
      "Choice: 0.to paint 1.medical treatment 2.to work 3.to eat\n",
      "Answer:  ASSISTANT: 3\n",
      "3\n",
      "3\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What type of sinks are shown?\n",
      "Choice: 0.bathroom 1.workstation 2.kitchen 3.laundry\n",
      "Answer:  ASSISTANT: 1\n",
      "1\n",
      "0\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: In what type of environment are they most likely riding skateboards?\n",
      "Choice: 0.beach 1.city 2.rural 3.suburban\n",
      "Answer:  ASSISTANT: 1\n",
      "1\n",
      "1\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: Is the man on the left platform going to board the train?\n",
      "Choice: 0.yes 1.absolutely no 2.probably yes 3.probably no\n",
      "Answer:  ASSISTANT: 2\n",
      "2\n",
      "1\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: This part of the house where is the girl is is called?\n",
      "Choice: 0.dinning room 1.kitchen 2.sitting room 3.bedroom\n",
      "Answer:  ASSISTANT: 3\n",
      "3\n",
      "3\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: They are likely having pizza at what kind of event?\n",
      "Choice: 0.family 1.gaming 2.academic 3.social\n",
      "Answer:  ASSISTANT: 3\n",
      "3\n",
      "2\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What are the people driving?\n",
      "Choice: 0.dirt bikes 1.monster truck 2.train 3.bus\n",
      "Answer:  ASSISTANT: 1\n",
      "1\n",
      "0\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: The bus is likely driving through which American city?\n",
      "Choice: 0.chicago 1.new york 2.philadelphia 3.boston\n",
      "Answer:  ASSISTANT: 1\n",
      "1\n",
      "1\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What drink might these be good in?\n",
      "Choice: 0.beer 1.milkshake 2.gin 3.coffee\n",
      "Answer:  ASSISTANT: 3\n",
      "3\n",
      "1\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What type of parking is available?\n",
      "Choice: 0.truck 1.airplane 2.bicycle 3.rv\n",
      "Answer:  ASSISTANT: 2\n",
      "2\n",
      "2\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What direction is the narrow end of the flag pointing?\n",
      "Choice: 0.north 1.south 2.east 3.west\n",
      "Answer:  ASSISTANT: 3\n",
      "3\n",
      "3\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: In what nation is this scene located?\n",
      "Choice: 0.spain 1.china 2.italy 3.france\n",
      "Answer:  ASSISTANT: 3\n",
      "3\n",
      "3\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What festive season are these fruits usually ingested?\n",
      "Choice: 0.liberty day 1.christmas 2.victory day 3.memorial day\n",
      "Answer:  ASSISTANT: 3\n",
      "3\n",
      "1\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What are the boats shaped like?\n",
      "Choice: 0.trains 1.tanks 2.cars 3.planes\n",
      "Answer:  ASSISTANT: 3\n",
      "3\n",
      "2\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What is the metal basket near the net used to hold?\n",
      "Choice: 0.tennis balls 1.marbles 2.bats 3.towels\n",
      "Answer:  ASSISTANT: 0\n",
      "0\n",
      "0\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What is likely to have happened?\n",
      "Choice: 0.dancing 1.eating 2.crashing 3.swimming\n",
      "Answer:  ASSISTANT: 2\n",
      "2\n",
      "2\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: Which vegetable on the pizza would be risky for someone with a certain allergy?\n",
      "Choice: 0.pepperoni 1.mushrooms 2.banana peppers 3.red peppers\n",
      "Answer:  ASSISTANT: 2\n",
      "2\n",
      "1\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: Which food has the least carbs?\n",
      "Choice: 0.soup 1.water 2.sandwich 3.buns\n",
      "Answer:  ASSISTANT: 3\n",
      "3\n",
      "0\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What vehicle is closest to the security guard?\n",
      "Choice: 0.silver car 1.two-wheeler 2.bluecar 3.dark car\n",
      "Answer:  ASSISTANT: 1\n",
      "1\n",
      "1\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: Why are the men wearing yellow vests?\n",
      "Choice: 0.visibility 1.fashion 2.warmth 3.costume\n",
      "Answer:  ASSISTANT: 0\n",
      "0\n",
      "0\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What is the skateboard balanced on?\n",
      "Choice: 0.post 1.air 2.chain 3.ground\n",
      "Answer:  ASSISTANT: 3\n",
      "3\n",
      "2\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What is the object in the middle called?\n",
      "Choice: 0.counter 1.island 2.table 3.desk\n",
      "Answer:  ASSISTANT: 1\n",
      "1\n",
      "1\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What is the gray street made up of?\n",
      "Choice: 0.asphalt 1.sand 2.stone 3.wood\n",
      "Answer:  ASSISTANT: 0\n",
      "0\n",
      "2\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: The name of the street is the same as the last name of what actress?\n",
      "Choice: 0.eva mendes 1.jessica biel 2.eva green 3.jessica alba\n",
      "Answer:  ASSISTANT: 2\n",
      "2\n",
      "1\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: How was the cake decorated?\n",
      "Choice: 0.drawn 1.piping tip 2.fork 3.sprinkled\n",
      "Answer:  ASSISTANT: 1\n",
      "1\n",
      "1\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: The green object on the smaller boat is used as what?\n",
      "Choice: 0.cabin 1.restroom 2.dining 3.kitchen\n",
      "Answer:  ASSISTANT: 3\n",
      "3\n",
      "1\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: Who has the same color hair as this woman?\n",
      "Choice: 0.phoebe tonkin 1.maria sharapova 2.serena williams 3.nina dobrev\n",
      "Answer:  ASSISTANT: 3\n",
      "3\n",
      "1\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: Why would you use this bag?\n",
      "Choice: 0.shop 1.travel 2.catch 3.preserve\n",
      "Answer:  ASSISTANT: 1\n",
      "1\n",
      "1\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What is being made by the man?\n",
      "Choice: 0.bow 1.kite 2.flag 3.anchor\n",
      "Answer:  ASSISTANT: 1\n",
      "1\n",
      "1\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What is the man in the gray suit on the left looking down to check?\n",
      "Choice: 0.phone 1.tablet 2.notebook 3.pager\n",
      "Answer:  ASSISTANT: 0\n",
      "0\n",
      "0\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: Which ingredient is the most flavorful?\n",
      "Choice: 0.mushrooms 1.fish 2.plate 3.broccoli\n",
      "Answer:  ASSISTANT: 1\n",
      "1\n",
      "1\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What are these cases for?\n",
      "Choice: 0.clothing 1.instruments 2.clothing 3.food\n",
      "Answer:  ASSISTANT: 2\n",
      "2\n",
      "0\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What pattern are the man's pants?\n",
      "Choice: 0.camouflage 1.plaid 2.floral 3.pinstripe\n",
      "Answer:  ASSISTANT: 1\n",
      "1\n",
      "0\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: In which major city is the woman most likely sitting outdoors?\n",
      "Choice: 0.paris 1.new york 2.johannesburg 3.london\n",
      "Answer:  ASSISTANT: 0\n",
      "0\n",
      "0\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: Where are these animals located?\n",
      "Choice: 0.museum 1.zoo 2.vet 3.wild\n",
      "Answer:  ASSISTANT: 3\n",
      "3\n",
      "3\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: In what location is the motorcycle parked most likely?\n",
      "Choice: 0.store 1.sidewalk 2.home 3.expo\n",
      "Answer:  ASSISTANT: 2\n",
      "2\n",
      "2\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What is the natural light streaming into the room through?\n",
      "Choice: 0.door 1.lightbulb 2.clock 3.candle\n",
      "Answer:  ASSISTANT: 2\n",
      "2\n",
      "2\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What is the white cream used for with the other foods?\n",
      "Choice: 0.drinking 1.cooking 2.dipping 3.heating\n",
      "Answer:  ASSISTANT: 2\n",
      "2\n",
      "2\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What can be seen through the buildings?\n",
      "Choice: 0.clouds 1.birds 2.more buildings 3.sunlight\n",
      "Answer:  ASSISTANT: 3\n",
      "3\n",
      "3\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What type of audience is the man likely speaking to?\n",
      "Choice: 0.protest 1.single person 2.political rally 3.meeting\n",
      "Answer:  ASSISTANT: 3\n",
      "3\n",
      "3\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What will be built here one day?\n",
      "Choice: 0.building 1.boat 2.car 3.house\n",
      "Answer:  ASSISTANT: 3\n",
      "3\n",
      "0\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What seems to be contained in the nook underneath the TV?\n",
      "Choice: 0.bookshelf 1.lamp 2.fireplace 3.stereo\n",
      "Answer:  ASSISTANT: 2\n",
      "2\n",
      "2\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What problem will the people on the ferry face?\n",
      "Choice: 0.earthquake 1.raining 2.sunburn 3.tsunami\n",
      "Answer:  ASSISTANT: 1\n",
      "1\n",
      "1\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: Why do the cattle have their heads down to the ground?\n",
      "Choice: 0.to eat 1.to drink 2.to play 3.to sleep\n",
      "Answer:  ASSISTANT: 0\n",
      "0\n",
      "0\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What state was the licence plate issues?\n",
      "Choice: 0.connecticut 1.rhode island 2.new jersey 3.new york\n",
      "Answer:  ASSISTANT: 3\n",
      "3\n",
      "3\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What are the people in the picture doing?\n",
      "Choice: 0.skating 1.laughing 2.jogging 3.angry\n",
      "Answer:  ASSISTANT: 2\n",
      "2\n",
      "0\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What type of city district is this?\n",
      "Choice: 0.government 1.warehouse 2.commercial 3.residential\n",
      "Answer:  ASSISTANT: 2\n",
      "2\n",
      "2\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What player is shown in the photo?\n",
      "Choice: 0.shortstop 1.catcher 2.position 3.first baseman\n",
      "Answer:  ASSISTANT: 3\n",
      "3\n",
      "2\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: Where are these cats located?\n",
      "Choice: 0.alley 1.home 2.vet 3.office\n",
      "Answer:  ASSISTANT: 1\n",
      "1\n",
      "1\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What is prohibited near the round road sign with a red cross on a blue background?\n",
      "Choice: 0.parking 1.turning 2.speeding 3.waving\n",
      "Answer:  ASSISTANT: 3\n",
      "3\n",
      "0\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: Where is this dog located?\n",
      "Choice: 0.office 1.home 2.zoo 3.vet\n",
      "Answer:  ASSISTANT: 1\n",
      "1\n",
      "1\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: Who is the woman dressed up as?\n",
      "Choice: 0.snow white 1.xena 2.maleficent 3.cinderella\n",
      "Answer:  ASSISTANT: 1\n",
      "1\n",
      "1\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What type of event might this be?\n",
      "Choice: 0.art show 1.car show 2.museum opening 3.race\n",
      "Answer:  ASSISTANT: 1\n",
      "1\n",
      "0\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What is the activity being performed?\n",
      "Choice: 0.show performance 1.training horse 2.riding horse 3.feeding horse\n",
      "Answer:  ASSISTANT: 2\n",
      "2\n",
      "0\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What color are the walls in the room?\n",
      "Choice: 0.orange 1.yellow 2.blue 3.green\n",
      "Answer:  ASSISTANT: 3\n",
      "3\n",
      "3\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: In which way are the adults shown here likely related to the child?\n",
      "Choice: 0.grandparents 1.strangers 2.friends 3.sister\n",
      "Answer:  ASSISTANT: 2\n",
      "2\n",
      "0\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What is served at the counter here?\n",
      "Choice: 0.fines 1.ice cream 2.alcohol 3.chinese\n",
      "Answer:  ASSISTANT: 2\n",
      "2\n",
      "2\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What type of tree is in front of the blue building?\n",
      "Choice: 0.palm tree 1.bonsai tree 2.maple tree 3.pine tree\n",
      "Answer:  ASSISTANT: 3\n",
      "3\n",
      "0\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What did the man use to get into the air?\n",
      "Choice: 0.kite 1.blimp 2.balloon 3.plane\n",
      "Answer:  ASSISTANT: 0\n",
      "0\n",
      "0\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What type of cuisine would be purchased here?\n",
      "Choice: 0.chinese 1.russian 2.italian 3.mexican\n",
      "Answer:  ASSISTANT: 3\n",
      "3\n",
      "3\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What type of bus is in traffic?\n",
      "Choice: 0.public 1.school 2.work 3.tour\n",
      "Answer:  ASSISTANT: 1\n",
      "1\n",
      "1\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: In what shape is the quiche cut?\n",
      "Choice: 0.triangles 1.stars 2.circles 3.rectangles\n",
      "Answer:  ASSISTANT: 2\n",
      "2\n",
      "0\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What kind of coating has been used?\n",
      "Choice: 0.polish 1.frosting 2.paint 3.varnish\n",
      "Answer:  ASSISTANT: 3\n",
      "3\n",
      "1\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: Which century was the item the woman is holding up invented in?\n",
      "Choice: 0.twentieth 1.twenty first 2.tenth 3.eighteenth\n",
      "Answer:  ASSISTANT: 1\n",
      "1\n",
      "0\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What genus of animal is visible here?\n",
      "Choice: 0.canine 1.porcine 2.feline 3.rodent\n",
      "Answer:  ASSISTANT: 3\n",
      "3\n",
      "2\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What brand is the red truck?\n",
      "Choice: 0.dodge 1.chevy 2.ford 3.toyota\n",
      "Answer:  ASSISTANT: 0\n",
      "0\n",
      "0\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: This meal was likely prepared using which method?\n",
      "Choice: 0.oven 1.crockpot 2.grill 3.stovetop\n",
      "Answer:  ASSISTANT: 2\n",
      "2\n",
      "2\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: The cat appears to be what type?\n",
      "Choice: 0.feral 1.housecat 2.pregnant 3.sheltered\n",
      "Answer:  ASSISTANT: 1\n",
      "1\n",
      "1\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What limits forward navigation?\n",
      "Choice: 0.traffic warden 1.road accident 2.red light 3.bad weather\n",
      "Answer:  ASSISTANT: 2\n",
      "2\n",
      "2\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What are the zebras doing?\n",
      "Choice: 0.grazing 1.sleeping 2.drinking 3.walking\n",
      "Answer:  ASSISTANT: 0\n",
      "0\n",
      "0\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: Why are the people behind the fence there?\n",
      "Choice: 0.coaching 1.spectating 2.relaxing 3.taking photos\n",
      "Answer:  ASSISTANT: 1\n",
      "1\n",
      "1\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: Which piece of clothing is unique to one person here?\n",
      "Choice: 0.collar 1.shirt 2.tie 3.vest\n",
      "Answer:  ASSISTANT: 2\n",
      "2\n",
      "3\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What type of container is the straw sticking out of?\n",
      "Choice: 0.pint glass 1.martini glass 2.mason jar 3.vase\n",
      "Answer:  ASSISTANT: 3\n",
      "3\n",
      "2\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: A person following what kind of diet is least likely to eat this meal?\n",
      "Choice: 0.atkins 1.weight watchers 2.vegetarian 3.ketogenic\n",
      "Answer:  ASSISTANT: 3\n",
      "3\n",
      "2\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What is placed on the ground that will eventually turn yellow?\n",
      "Choice: 0.bananas 1.pears 2.tomatoes 3.apples\n",
      "Answer:  ASSISTANT: 0\n",
      "0\n",
      "0\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What is in the bottles?\n",
      "Choice: 0.beer 1.liquer 2.water 3.juice\n",
      "Answer:  ASSISTANT: 1\n",
      "1\n",
      "1\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: Which food on the plate grows in the ground?\n",
      "Choice: 0.chicken 1.carrot 2.dried cranberry 3.bread\n",
      "Answer:  ASSISTANT: 1\n",
      "1\n",
      "1\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What theme park attraction are they most likely visiting?\n",
      "Choice: 0.disney world 1.disneyland 2.universal studios 3.six flags\n",
      "Answer:  ASSISTANT: 1\n",
      "1\n",
      "1\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What is in the photo above the TV?\n",
      "Choice: 0.cat 1.boy 2.woman 3.dog\n",
      "Answer:  ASSISTANT: 3\n",
      "3\n",
      "2\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: The temperature outside is likely what range?\n",
      "Choice: 0.below freezing 1.hot 2.cool 3.very humid\n",
      "Answer:  ASSISTANT: 2\n",
      "2\n",
      "1\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What kind of weather was there?\n",
      "Choice: 0.hail 1.rain 2.sun 3.snow\n",
      "Answer:  ASSISTANT: 1\n",
      "1\n",
      "1\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What is the facade that the couple is being interviewed in likely designed to be?\n",
      "Choice: 0.radio 1.camera 2.building 3.tv\n",
      "Answer:  ASSISTANT: 3\n",
      "3\n",
      "3\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What level of a house is this room located in?\n",
      "Choice: 0.basement 1.ground 2.second 3.third\n",
      "Answer:  ASSISTANT: 1\n",
      "1\n",
      "0\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What type of birds are these?\n",
      "Choice: 0.captive 1.desert 2.arctic 3.aquatic\n",
      "Answer:  ASSISTANT: 3\n",
      "3\n",
      "3\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What country headquarters this plane company?\n",
      "Choice: 0.canada 1.japan 2.usa 3.uk\n",
      "Answer:  ASSISTANT: 3\n",
      "3\n",
      "2\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What other sport besides ping pong is played by someone in this household?\n",
      "Choice: 0.lacrosse 1.hockey 2.baseball 3.tennis\n",
      "Answer:  ASSISTANT: 3\n",
      "3\n",
      "3\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: Which team is on offense?\n",
      "Choice: 0.red 1.neither 2.blue 3.both\n",
      "Answer:  ASSISTANT: 3\n",
      "3\n",
      "0\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What object should never get wet?\n",
      "Choice: 0.laptop 1.computer monitor 2.tv 3.jacket\n",
      "Answer:  ASSISTANT: 3\n",
      "3\n",
      "0\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What do the larger elephants still have intact?\n",
      "Choice: 0.tusks 1.pythons 2.horns 3.antlers\n",
      "Answer:  ASSISTANT: 2\n",
      "2\n",
      "0\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What kind of room is on the left of the yellow train?\n",
      "Choice: 0.nursery room 1.bathroom 2.changing room 3.waiting room\n",
      "Answer:  ASSISTANT: 3\n",
      "3\n",
      "3\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: Which vehicle is closest to the rectangular blue sign?\n",
      "Choice: 0.blue car 1.red bus 2.motorcycle 3.light car\n",
      "Answer:  ASSISTANT: 3\n",
      "3\n",
      "1\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What vehicle is shown in the photo?\n",
      "Choice: 0.airplane 1.bus 2.train 3.car\n",
      "Answer:  ASSISTANT: 3\n",
      "3\n",
      "0\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What kind of bag is this?\n",
      "Choice: 0.suitcase 1.backpack 2.purse 3.briefcase\n",
      "Answer:  ASSISTANT: 3\n",
      "3\n",
      "0\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: Why are the wood platforms strapped to the elephants?\n",
      "Choice: 0.to punish 1.to plow 2.to groom 3.to ride\n",
      "Answer:  ASSISTANT: 3\n",
      "3\n",
      "3\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What is the train riding on?\n",
      "Choice: 0.street 1.train tracks 2.clay 3.grass\n",
      "Answer:  ASSISTANT: 1\n",
      "1\n",
      "1\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What is the man taking?\n",
      "Choice: 0.walk 1.picture 2.watch 3.pee\n",
      "Answer:  ASSISTANT: 1\n",
      "1\n",
      "1\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What item is on the bottom shelf near the TV?\n",
      "Choice: 0.cars 1.pictures 2.swords 3.speakers\n",
      "Answer:  ASSISTANT: 3\n",
      "3\n",
      "3\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What city is mentioned on the front of the bus?\n",
      "Choice: 0.new york 1.los angeles 2.chicago 3.seattle\n",
      "Answer:  ASSISTANT: 3\n",
      "3\n",
      "3\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What expression are these children making?\n",
      "Choice: 0.confused 1.smiling 2.crying 3.angry\n",
      "Answer:  ASSISTANT: 1\n",
      "1\n",
      "1\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What video game system is the boy playing on?\n",
      "Choice: 0.nintendo wii 1.playstation 3 2.xbox one 3.playstation 4\n",
      "Answer:  ASSISTANT: 0\n",
      "0\n",
      "0\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What does Fidelity specialize in?\n",
      "Choice: 0.travel 1.insurance 2.investments 3.rentals\n",
      "Answer:  ASSISTANT: 2\n",
      "2\n",
      "2\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: Which is the fruit?\n",
      "Choice: 0.meat 1.chocolate 2.nuts 3.orange slices\n",
      "Answer:  ASSISTANT: 3\n",
      "3\n",
      "3\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What is the green box near the red stapler on the desk used to hold?\n",
      "Choice: 0.tissues 1.pins 2.pens 3.pencils\n",
      "Answer:  ASSISTANT: 3\n",
      "3\n",
      "0\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: How many bake pans were utilized?\n",
      "Choice: 0.one 1.none 2.four 3.three\n",
      "Answer:  ASSISTANT: 3\n",
      "3\n",
      "2\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What are some of the zebras standing in in the middle of the photo?\n",
      "Choice: 0.grass 1.water 2.mud 3.rocks\n",
      "Answer:  ASSISTANT: 2\n",
      "2\n",
      "1\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: How many people have their arms around the woman?\n",
      "Choice: 0.four 1.one 2.five 3.three\n",
      "Answer:  ASSISTANT: 1\n",
      "1\n",
      "1\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What city name is shown in the background?\n",
      "Choice: 0.los angeles 1.riverton 2.new york 3.omaha\n",
      "Answer:  ASSISTANT: 3\n",
      "3\n",
      "3\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What is the dark colored car to the far left in the middle doing?\n",
      "Choice: 0.turning left 1.turning right 2.parking 3.reversing\n",
      "Answer:  ASSISTANT: 2\n",
      "2\n",
      "0\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: Are the people boarding this train?\n",
      "Choice: 0.absolutely no 1.probably yes 2.probably no 3.yes\n",
      "Answer:  ASSISTANT: 3\n",
      "3\n",
      "0\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What is purpose of this wooden board?\n",
      "Choice: 0.entertaining kids 1.decoration 2.street sign 3.advertisement\n",
      "Answer:  ASSISTANT: 3\n",
      "3\n",
      "3\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What video game system is the man playing?\n",
      "Choice: 0.xbox one 1.playstation 5 2.nintendo wii 3.atari\n",
      "Answer:  ASSISTANT: 2\n",
      "2\n",
      "2\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: Where are the buses with blue trim probably assembled?\n",
      "Choice: 0.stadium 1.lot 2.lane 3.terminal\n",
      "Answer:  ASSISTANT: 3\n",
      "3\n",
      "3\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What kind of pizza is this?\n",
      "Choice: 0.margarita 1.deep dish 2.pepperoni 3.loaded\n",
      "Answer:  ASSISTANT: 3\n",
      "3\n",
      "0\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: When it comes to the child what is he or she doing?\n",
      "Choice: 0.roller blading 1.kicking 2.karate 3.skateboarding\n",
      "Answer:  ASSISTANT: 3\n",
      "3\n",
      "3\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What is the small house behind the cattle made up of?\n",
      "Choice: 0.plastic 1.reef 2.stone 3.thatch\n",
      "Answer:  ASSISTANT: 2\n",
      "2\n",
      "2\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What type of transportation is shown?\n",
      "Choice: 0.rail 1.road 2.water 3.air\n",
      "Answer:  ASSISTANT: 0\n",
      "0\n",
      "0\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What is the little girl doing?\n",
      "Choice: 0.drinking 1.yelling 2.eating 3.singing\n",
      "Answer:  ASSISTANT: 2\n",
      "2\n",
      "2\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What type of area is shown?\n",
      "Choice: 0.rural 1.medical 2.commercial 3.residential\n",
      "Answer:  ASSISTANT: 2\n",
      "2\n",
      "2\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What appliance is unhooked and placed by the sink?\n",
      "Choice: 0.dishwasher 1.stove/oven 2.trash compactor 3.icemaker\n",
      "Answer:  ASSISTANT: 2\n",
      "2\n",
      "1\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: Which food on the dish is a meat?\n",
      "Choice: 0.broccoli 1.turkey 2.rice 3.green beans\n",
      "Answer:  ASSISTANT: 1\n",
      "1\n",
      "1\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: Which body part of the cow could you look at to find out which identity and/or owner the cow has?\n",
      "Choice: 0.ear 1.foot 2.rump 3.knee\n",
      "Answer:  ASSISTANT: 3\n",
      "3\n",
      "0\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: Who is the manufacturer of this laptop?\n",
      "Choice: 0.apple 1.hp 2.dell 3.compaq\n",
      "Answer:  ASSISTANT: 0\n",
      "0\n",
      "1\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What is the person using to eat the pizza?\n",
      "Choice: 0.knife 1.spoon 2.none 3.fork\n",
      "Answer:  ASSISTANT: 3\n",
      "3\n",
      "3\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What are the white rocks for?\n",
      "Choice: 0.breaking 1.prevent fire 2.water retainment 3.decoration\n",
      "Answer:  ASSISTANT: 2\n",
      "2\n",
      "1\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What animal has similar color to the flower in the picture on the left side of the room?\n",
      "Choice: 0.koala 1.rooster 2.zebra 3.panda\n",
      "Answer:  ASSISTANT: 3\n",
      "3\n",
      "1\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What other animal is this animal traditionally an enemy of?\n",
      "Choice: 0.tigers 1.cats 2.elephants 3.mice\n",
      "Answer:  ASSISTANT: 3\n",
      "3\n",
      "1\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What left the blue marks on the ground near the fire hydrant?\n",
      "Choice: 0.paint 1.wind 2.fruit 3.animals\n",
      "Answer:  ASSISTANT: 0\n",
      "0\n",
      "0\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What kind of a person usually eats food like this?\n",
      "Choice: 0.obese 1.competitive eater 2.glutton 3.nutritionist\n",
      "Answer:  ASSISTANT: 3\n",
      "3\n",
      "3\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: Which person would be the coldest?\n",
      "Choice: 0.left 1.middle 2.right 3.none\n",
      "Answer:  ASSISTANT: 3\n",
      "3\n",
      "1\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What pattern is on the bottom of the skateboard?\n",
      "Choice: 0.zigzag 1.plaid 2.stripes 3.polka dots\n",
      "Answer:  ASSISTANT: 3\n",
      "3\n",
      "3\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: How many drinkers are sucking down their beverages?\n",
      "Choice: 0.three 1.two 2.none 3.one\n",
      "Answer:  ASSISTANT: 3\n",
      "3\n",
      "0\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What does the taller bottle contain?\n",
      "Choice: 0.beer 1.juice 2.champagne 3.water\n",
      "Answer:  ASSISTANT: 3\n",
      "3\n",
      "3\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: How do these people know each other?\n",
      "Choice: 0.coworkers 1.spouses 2.siblings 3.classmates\n",
      "Answer:  ASSISTANT: 3\n",
      "3\n",
      "3\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What might you mix with the alcoholic drink named?\n",
      "Choice: 0.milk 1.coke 2.beer 3.gin\n",
      "Answer:  ASSISTANT: 3\n",
      "3\n",
      "1\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What type of vehicle is this?\n",
      "Choice: 0.construction 1.cargo 2.watercraft 3.passenger\n",
      "Answer:  ASSISTANT: 3\n",
      "3\n",
      "3\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What material are the white cups?\n",
      "Choice: 0.wood 1.glass 2.paper 3.plastic\n",
      "Answer:  ASSISTANT: 3\n",
      "3\n",
      "2\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What color is the floor?\n",
      "Choice: 0.brown 1.green 2.blue 3.purple\n",
      "Answer:  ASSISTANT: 3\n",
      "3\n",
      "0\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What is placed inside this meter?\n",
      "Choice: 0.paper 1.paint 2.water 3.money\n",
      "Answer:  ASSISTANT: 3\n",
      "3\n",
      "3\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: What appliance is shown?\n",
      "Choice: 0.dryer 1.microwave 2.washer 3.toaster\n",
      "Answer:  ASSISTANT: 3\n",
      "3\n",
      "3\n",
      "ER:  \n",
      "I will give you a question and choices, return only the index of the choice\n",
      "Question: Why does the couple standing in the boat?\n",
      "Choice: 0.fun 1.reduce stress 2.tradition 3.spend time\n",
      "Answer:  ASSISTANT: 3\n",
      "3\n",
      "3\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m prompt \u001b[38;5;241m=\u001b[39m processor\u001b[38;5;241m.\u001b[39mapply_chat_template(conversation, add_generation_prompt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     24\u001b[0m inputs \u001b[38;5;241m=\u001b[39m processor(images\u001b[38;5;241m=\u001b[39mraw_image, text\u001b[38;5;241m=\u001b[39mprompt, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;241m0\u001b[39m, torch\u001b[38;5;241m.\u001b[39mfloat16)\n\u001b[0;32m---> 26\u001b[0m generated_ids \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m model_response \u001b[38;5;241m=\u001b[39m processor\u001b[38;5;241m.\u001b[39mdecode(generated_ids[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m2\u001b[39m:], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(model_response)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/transformers/generation/utils.py:2215\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   2207\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   2208\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   2209\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   2210\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   2211\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   2212\u001b[0m     )\n\u001b[1;32m   2214\u001b[0m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[0;32m-> 2215\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2216\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2217\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2218\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2219\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2220\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2221\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2222\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2223\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2225\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[1;32m   2226\u001b[0m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[1;32m   2227\u001b[0m     beam_scorer \u001b[38;5;241m=\u001b[39m BeamSearchScorer(\n\u001b[1;32m   2228\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   2229\u001b[0m         num_beams\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2234\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mmax_length,\n\u001b[1;32m   2235\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/transformers/generation/utils.py:3206\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   3203\u001b[0m model_inputs\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_hidden_states\u001b[39m\u001b[38;5;124m\"\u001b[39m: output_hidden_states} \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;28;01melse\u001b[39;00m {})\n\u001b[1;32m   3205\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 3206\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   3208\u001b[0m \u001b[38;5;66;03m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[39;00m\n\u001b[1;32m   3209\u001b[0m model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_model_kwargs_for_generation(\n\u001b[1;32m   3210\u001b[0m     outputs,\n\u001b[1;32m   3211\u001b[0m     model_kwargs,\n\u001b[1;32m   3212\u001b[0m     is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   3213\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/transformers/models/llava/modeling_llava.py:540\u001b[0m, in \u001b[0;36mLlavaForConditionalGeneration.forward\u001b[0;34m(self, input_ids, pixel_values, attention_mask, position_ids, past_key_values, inputs_embeds, vision_feature_layer, vision_feature_select_strategy, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, num_logits_to_keep)\u001b[0m\n\u001b[1;32m    537\u001b[0m     image_features \u001b[38;5;241m=\u001b[39m image_features\u001b[38;5;241m.\u001b[39mto(inputs_embeds\u001b[38;5;241m.\u001b[39mdevice, inputs_embeds\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m    538\u001b[0m     inputs_embeds \u001b[38;5;241m=\u001b[39m inputs_embeds\u001b[38;5;241m.\u001b[39mmasked_scatter(special_image_mask, image_features)\n\u001b[0;32m--> 540\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlanguage_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    541\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    542\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    543\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    544\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    545\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    546\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    547\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    548\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    549\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_logits_to_keep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_logits_to_keep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    553\u001b[0m logits \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    555\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/transformers/models/llama/modeling_llama.py:1190\u001b[0m, in \u001b[0;36mLlamaForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, num_logits_to_keep, **loss_kwargs)\u001b[0m\n\u001b[1;32m   1187\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m   1189\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1190\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1192\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1193\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1194\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1196\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1197\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1198\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1200\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1201\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1203\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1204\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpretraining_tp \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/transformers/models/llama/modeling_llama.py:945\u001b[0m, in \u001b[0;36mLlamaModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    933\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    934\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    935\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    942\u001b[0m         position_embeddings,\n\u001b[1;32m    943\u001b[0m     )\n\u001b[1;32m    944\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 945\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    947\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    948\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    949\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    950\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    951\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    952\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    953\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    954\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    956\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    958\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/transformers/models/llama/modeling_llama.py:676\u001b[0m, in \u001b[0;36mLlamaDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    673\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layernorm(hidden_states)\n\u001b[1;32m    675\u001b[0m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[0;32m--> 676\u001b[0m hidden_states, self_attn_weights, present_key_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    680\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    683\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    684\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    685\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    686\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    687\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[1;32m    689\u001b[0m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/transformers/models/llama/modeling_llama.py:577\u001b[0m, in \u001b[0;36mLlamaSdpaAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    576\u001b[0m     cos, sin \u001b[38;5;241m=\u001b[39m position_embeddings\n\u001b[0;32m--> 577\u001b[0m query_states, key_states \u001b[38;5;241m=\u001b[39m \u001b[43mapply_rotary_pos_emb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msin\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;66;03m# sin and cos are specific to RoPE models; cache_position needed for the static cache\u001b[39;00m\n\u001b[1;32m    581\u001b[0m     cache_kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msin\u001b[39m\u001b[38;5;124m\"\u001b[39m: sin, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcos\u001b[39m\u001b[38;5;124m\"\u001b[39m: cos, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcache_position\u001b[39m\u001b[38;5;124m\"\u001b[39m: cache_position}\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/transformers/models/llama/modeling_llama.py:225\u001b[0m, in \u001b[0;36mapply_rotary_pos_emb\u001b[0;34m(q, k, cos, sin, position_ids, unsqueeze_dim)\u001b[0m\n\u001b[1;32m    223\u001b[0m sin \u001b[38;5;241m=\u001b[39m sin\u001b[38;5;241m.\u001b[39munsqueeze(unsqueeze_dim)\n\u001b[1;32m    224\u001b[0m q_embed \u001b[38;5;241m=\u001b[39m (q \u001b[38;5;241m*\u001b[39m cos) \u001b[38;5;241m+\u001b[39m (rotate_half(q) \u001b[38;5;241m*\u001b[39m sin)\n\u001b[0;32m--> 225\u001b[0m k_embed \u001b[38;5;241m=\u001b[39m (k \u001b[38;5;241m*\u001b[39m cos) \u001b[38;5;241m+\u001b[39m (\u001b[43mrotate_half\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m sin)\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m q_embed, k_embed\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/transformers/models/llama/modeling_llama.py:195\u001b[0m, in \u001b[0;36mrotate_half\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    191\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrope_type\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdynamic\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    192\u001b[0m         \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 195\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrotate_half\u001b[39m(x):\n\u001b[1;32m    196\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Rotates half the hidden dims of the input.\"\"\"\u001b[39;00m\n\u001b[1;32m    197\u001b[0m     x1 \u001b[38;5;241m=\u001b[39m x[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, : x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "correct_count = 0\n",
    "\n",
    "for dataset_example in aokvqa_dataset:\n",
    "    question = dataset_example['question']\n",
    "    choices = dataset_example['choices']\n",
    "    correct_choice = choices[dataset_example['correct_choice_idx']]\n",
    "    correct_idx = dataset_example['correct_choice_idx']\n",
    "    \n",
    "    image_path = get_coco_path('val', dataset_example['image_id'], coco_dir)\n",
    "    raw_image = Image.open(image_path)\n",
    "\n",
    "    conversation = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"image\"},\n",
    "                {\"type\": \"text\", \"text\": \"I will give you a question and choices, return only the index of the choice\\n\"+\"Question: \"+question+\"\\nChoice: \"\\\n",
    "                 +\"0.\"+choices[0]+\" 1.\"+choices[1]+\" 2.\"+choices[2]+\" 3.\"+choices[3]+\"\\nAnswer: \"},\n",
    "                # {\"type\": \"image\"},\n",
    "            ],\n",
    "        },\n",
    "    ]\n",
    "    prompt = processor.apply_chat_template(conversation, add_generation_prompt=True)\n",
    "    inputs = processor(images=raw_image, text=prompt, return_tensors='pt').to(0, torch.float16)\n",
    "\n",
    "    generated_ids = model.generate(**inputs, max_new_tokens=5, do_sample=False)\n",
    "    model_response = processor.decode(generated_ids[0][2:], skip_special_tokens=True)\n",
    "\n",
    "    print(model_response)\n",
    "    print(model_response[-1])\n",
    "    print(correct_idx)\n",
    "    \n",
    "    if correct_idx == model_response[-1]:\n",
    "        correct_count += 1\n",
    "\n",
    "print(f\"Number of accurate items: {correct_count} out of {len(aokvqa_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6e8578c8-4e14-45d5-8aa2-48b36ab38794",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "correct_count = 0\n",
    "logits_probs_data = []\n",
    "\n",
    "for dataset_example in aokvqa_dataset:\n",
    "    question = dataset_example['question']\n",
    "    choices = dataset_example['choices']\n",
    "    correct_choice = choices[dataset_example['correct_choice_idx']]\n",
    "    correct_idx = dataset_example['correct_choice_idx']\n",
    "    \n",
    "    image_path = get_coco_path('val', dataset_example['image_id'], coco_dir)\n",
    "    raw_image = Image.open(image_path)\n",
    "\n",
    "    conversation = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"image\"},\n",
    "                {\"type\": \"text\", \"text\": \"I will give you a question and choices, return only the index of the choice\\n\"+\"Question: \"+question+\"\\nChoice: \"\\\n",
    "                 +\"0.\"+choices[0]+\" 1.\"+choices[1]+\" 2.\"+choices[2]+\" 3.\"+choices[3]+\"\\nAnswer: \"},\n",
    "                # {\"type\": \"image\"},\n",
    "            ],\n",
    "        },\n",
    "    ]\n",
    "    prompt = processor.apply_chat_template(conversation, add_generation_prompt=True)\n",
    "    inputs = processor(images=raw_image, text=prompt, return_tensors='pt').to(0, torch.float16)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(**inputs)\n",
    "        logits = output.logits\n",
    "        \n",
    "    generated_ids = model.generate(**inputs, max_new_tokens=5, do_sample=False)\n",
    "    model_response = processor.decode(generated_ids[0][2:], skip_special_tokens=True)\n",
    "\n",
    "    token_probs = []\n",
    "    for i, token_id in enumerate(generated_ids[0]):\n",
    "        token_logit = logits[0, i]  # logits for all tokens at position i\n",
    "        token_prob = torch.nn.functional.softmax(token_logit, dim=-1)[token_id].item()\n",
    "        token_probs.append(token_prob)\n",
    "        \n",
    "    logits_probs_data.append({\n",
    "        \"question_id\": dataset_example['question_id'],\n",
    "        \"model_response\": model_response,\n",
    "        \"logits\": [logits[0, i, token_id].item() for i, token_id in enumerate(generated_ids[0])],\n",
    "        \"probabilities\": token_probs\n",
    "    })\n",
    "\n",
    "    # print(repr(correct_idx))\n",
    "    # print(repr(model_response[-1]))\n",
    "    # print(str(correct_idx).strip() == str(model_response[-1]).strip())\n",
    "    if str(correct_idx).strip() == str(model_response[-1]).strip():\n",
    "        correct_count += 1\n",
    "\n",
    "print(f\"Number of accurate items: {correct_count} out of {len(aokvqa_dataset)}\")\n",
    "\n",
    "# Print logits and probabilities for analysis\n",
    "for data in logits_probs_data:\n",
    "    print(f\"Question ID: {data['question_id']}\")\n",
    "    print(f\"Model Response: {data['model_response']}\")\n",
    "    print(\"Logits:\", data[\"logits\"])\n",
    "    print(\"Probabilities:\", data[\"probabilities\"])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5a1482ec-03e8-417a-9fa3-42910882eb8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of accurate items: 740 out of 1145\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of accurate items: {correct_count} out of {len(aokvqa_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "da843ef8-3e0b-4e99-bf33-16de9eddd2dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of probabilities: 0.006042955737364919\n"
     ]
    }
   ],
   "source": [
    "mean_probability = sum(data[\"probabilities\"]) / len(data[\"probabilities\"])\n",
    "print(\"Mean of probabilities:\", mean_probability)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3c7fe77-7dbc-48da-aee3-d1cc1f512b07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89dd31af1eed468e80f9ccd5f2cf8358",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 21.98 GiB of which 6.44 MiB is free. Including non-PyTorch memory, this process has 21.96 GiB memory in use. Of the allocated memory 21.61 GiB is allocated by PyTorch, and 49.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 12\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Load the model and processor\u001b[39;00m\n\u001b[1;32m      7\u001b[0m model_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllava-hf/llava-1.5-7b-hf\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      8\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mLlavaForConditionalGeneration\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat16\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m---> 12\u001b[0m \u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m processor \u001b[38;5;241m=\u001b[39m AutoProcessor\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_id)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Define a chat history and use `apply_chat_template` to get correctly formatted prompt\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/transformers/modeling_utils.py:3157\u001b[0m, in \u001b[0;36mPreTrainedModel.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3152\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_present_in_args:\n\u001b[1;32m   3153\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   3154\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou cannot cast a GPTQ model in a new `dtype`. Make sure to load the model using `from_pretrained` using the desired\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3155\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `dtype` by passing the correct `torch_dtype` argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3156\u001b[0m         )\n\u001b[0;32m-> 3157\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/torch/nn/modules/module.py:1340\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1337\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1338\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m-> 1340\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/torch/nn/modules/module.py:900\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 900\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    903\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    904\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    905\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    910\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    911\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/torch/nn/modules/module.py:900\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 900\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    903\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    904\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    905\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    910\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    911\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: Module._apply at line 900 (3 times)]\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/torch/nn/modules/module.py:900\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 900\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    903\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    904\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    905\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    910\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    911\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/torch/nn/modules/module.py:927\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    924\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    925\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    926\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 927\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    928\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    930\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/torch/nn/modules/module.py:1326\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1320\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m   1321\u001b[0m             device,\n\u001b[1;32m   1322\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1323\u001b[0m             non_blocking,\n\u001b[1;32m   1324\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[1;32m   1325\u001b[0m         )\n\u001b[0;32m-> 1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1327\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1328\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1330\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1331\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 21.98 GiB of which 6.44 MiB is free. Including non-PyTorch memory, this process has 21.96 GiB memory in use. Of the allocated memory 21.61 GiB is allocated by PyTorch, and 49.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from PIL import Image\n",
    "import torch\n",
    "from transformers import AutoProcessor, LlavaForConditionalGeneration\n",
    "\n",
    "# Load the model and processor\n",
    "model_id = \"llava-hf/llava-1.5-7b-hf\"\n",
    "model = LlavaForConditionalGeneration.from_pretrained(\n",
    "    model_id, \n",
    "    torch_dtype=torch.float16, \n",
    "    low_cpu_mem_usage=True, \n",
    ").to(0)\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "\n",
    "# Define a chat history and use `apply_chat_template` to get correctly formatted prompt\n",
    "conversation = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"text\", \"text\": \"What are these?\"},\n",
    "            {\"type\": \"image\"},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "prompt = processor.apply_chat_template(conversation, add_generation_prompt=True)\n",
    "\n",
    "# Load and preprocess the image\n",
    "image_file = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n",
    "raw_image = Image.open(requests.get(image_file, stream=True).raw)\n",
    "inputs = processor(images=raw_image, text=prompt, return_tensors='pt').to(0, torch.float16)\n",
    "\n",
    "# Forward pass to get logits\n",
    "with torch.no_grad():\n",
    "    output = model(**inputs)\n",
    "    logits = output.logits  # Shape: (batch_size, sequence_length, vocab_size)\n",
    "\n",
    "# Generate the output tokens using model.generate\n",
    "generated_ids = model.generate(**inputs, max_new_tokens=1, do_sample=False)\n",
    "\n",
    "# Decode the generated tokens to get the actual output\n",
    "output_text = processor.decode(generated_ids[0][2:], skip_special_tokens=True)\n",
    "print(\"Model Output:\", output_text)\n",
    "\n",
    "# Extract probabilities specifically for the generated tokens\n",
    "token_probs = []\n",
    "for i, token_id in enumerate(generated_ids[0]):\n",
    "    # Apply softmax only for the logits of this specific token's position\n",
    "    token_logit = logits[0, i]  # logits for all tokens at position i\n",
    "    token_prob = torch.nn.functional.softmax(token_logit, dim=-1)[token_id].item()  # probability of the specific token\n",
    "    token_probs.append(token_prob)\n",
    "\n",
    "# Print each generated token with its probability\n",
    "print(\"\\nToken probabilities for each token in the output:\")\n",
    "for token, prob in zip(processor.tokenizer.convert_ids_to_tokens(generated_ids[0]), token_probs):\n",
    "    print(f\"Token: {token}, Probability: {prob}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0700305f-1aa0-43b0-96cd-08b994702200",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "baseline",
   "language": "python",
   "name": "baseline"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
