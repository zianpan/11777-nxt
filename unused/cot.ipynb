{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/aokvqa/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 5/5 [00:05<00:00,  1.01s/it]\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from llama import Llama32\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from transformers import MllamaForConditionalGeneration, AutoProcessor\n",
    "import os\n",
    "import glob\n",
    "from tqdm import trange\n",
    "import re\n",
    "from utls import *\n",
    "\n",
    "to_load = True\n",
    "if to_load:\n",
    "    model = Llama32()\n",
    "    to_load = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PromptGenerator:\n",
    "\n",
    "    def __init__(self,):\n",
    "        # self.model = model\n",
    "        # self.model.eval()\n",
    "        # self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        # self.model.to(self.device)\n",
    "        pass\n",
    "\n",
    "\n",
    "        \n",
    "    def base_oneshot_generator(self,question, choices, rationale, direct_ans, base_ans):\n",
    "        prompt = f\"Question: {question}\\nChoices: A. {choices[0]} B. {choices[1]} C. {choices[2]} D. {choices[3]}\\nRationale: {{{''.join(rationale)}}}\\nAnswer: {{{toABCD[base_ans]}}}\"\n",
    "        return prompt\n",
    "\n",
    "    def base_fewshot_generator(self,val_aokvqa,coco_id_filename, num_shots = 3):\n",
    "        prompt_list = []\n",
    "        sample_used = set()\n",
    "        for i in range(num_shots):\n",
    "            meta_data_one_sample = val_aokvqa[i]\n",
    "        # meta_data_one_sample\n",
    "            # TODO modify base_path\n",
    "            base_path = \"/home/ubuntu/data/coco/val2017/\"\n",
    "            img_id = meta_data_one_sample[\"image_id\"]\n",
    "            sample_used.add(img_id)\n",
    "            img_file = coco_id_filename[img_id]\n",
    "            img_path = base_path + img_file  \n",
    "            base_ans = meta_data_one_sample[\"correct_choice_idx\"]\n",
    "            rationale =  meta_data_one_sample['rationales']\n",
    "            direct_ans = meta_data_one_sample['direct_answers']\n",
    "            toABCD = {0:'A', 1:'B', 2:'C', 3:'D'}\n",
    "\n",
    "            question = meta_data_one_sample[\"question\"]\n",
    "            choices = meta_data_one_sample[\"choices\"]\n",
    "            prompt = self.base_oneshot_generator(question, choices, rationale, direct_ans, base_ans)\n",
    "            prompt_list.append(prompt)\n",
    "            \n",
    "        return '\\n'.join(prompt_list), sample_used\n",
    "\n",
    "\n",
    "    def question_generator(self,question, choices):\n",
    "        prompt = f\"Question: {question}\\nChoices: A. {choices[0]} B. {choices[1]} C. {choices[2]} D. {choices[3]}\\nRationale: {{FILL IN Rationale}} Answer: {{FILL IN Answer}}\"\n",
    "        return prompt\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pg = PromptGenerator()\n",
    "val_aokvqa, coco_val_caption, coco_id_filename = prepare_dataset()\n",
    "val_aokvqa, coco_val_caption, coco_id_filename = prepare_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You task is to select one of the four following options based on the image and the question. Specifically, you need to output {{A }} or {{B}} or {{C}}or {{D}} surrounded by curly braces as well as rationales of why you chose that option.\n",
    "The rationales should also include in curly braces the answer to the question.\n",
    "\n",
    "Here are some examples that you can follow:\n",
    "\n",
    "Question: What is in the motorcyclist's mouth?\n",
    "Choices: A. toothpick B. food C. popsicle stick D. cigarette\n",
    "Rationale: {He's smoking while riding.The motorcyclist has a lit cigarette in his mouth while he rides on the street.The man is smoking.}\n",
    "Answer: {D}\n",
    "\n",
    "Question: Which number birthday is probably being celebrated?\n",
    "Choices: A. one B. ten C. nine D. thirty\n",
    "Rationale: {There is a birthday cake on the table with the number 30 written in icing.The cake says 30.The numerals three and zero are written on the cake, which indicates the person is 30 years of age as of the birthdate.}\n",
    "Answer: {D}\n",
    "\n",
    "Question: What best describes the pool of water?\n",
    "Choices: A. frozen B. fresh C. dirty D. boiling\n",
    "Rationale: {The pool is dark brown.It it brown and surrounded with mud.The pool is dirty.}\n",
    "Answer: {C}\n",
    "\n",
    "Now, it's your turn. Again, remember to put your answer in curly braces. Here is the question you need to answer.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/26 [00:05<02:28,  5.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 2/26 [00:11<02:17,  5.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 3/26 [00:18<02:20,  6.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 4/26 [00:24<02:17,  6.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 5/26 [00:33<02:34,  7.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 6/26 [00:36<01:54,  5.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The man on the right is wearing jeans, which are typically made of denim. The man is wearing denim pants.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 7/26 [00:42<01:51,  5.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 8/26 [00:48<01:43,  5.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 9/26 [00:50<01:21,  4.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 10/26 [00:55<01:16,  4.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 11/26 [00:59<01:10,  4.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 12/26 [01:05<01:08,  4.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 13/26 [01:11<01:07,  5.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 14/26 [01:16<01:01,  5.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 15/26 [01:20<00:52,  4.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 16/26 [01:25<00:49,  4.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 17/26 [01:32<00:50,  5.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 18/26 [01:37<00:43,  5.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 19/26 [01:41<00:34,  4.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 20/26 [01:44<00:26,  4.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 21/26 [01:48<00:20,  4.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 22/26 [01:52<00:16,  4.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 23/26 [01:57<00:13,  4.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 24/26 [02:01<00:08,  4.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 25/26 [02:04<00:03,  3.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [02:07<00:00,  4.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "for i in trange(4,1100):\n",
    "    meta_data_one_sample = val_aokvqa[i]\n",
    "    base_path = \"/home/ubuntu/data/coco/val2017/\"\n",
    "\n",
    "    toABCD = {0:'A', 1:'B', 2:'C', 3:'D'}\n",
    "\n",
    "    img_id = meta_data_one_sample[\"image_id\"]\n",
    "    img_file = coco_id_filename[img_id]\n",
    "    img_path = base_path + img_file  \n",
    "    base_ans = toABCD[meta_data_one_sample[\"correct_choice_idx\"]]\n",
    "    rationale =  meta_data_one_sample['rationales']\n",
    "    direct_ans = meta_data_one_sample['direct_answers']\n",
    "\n",
    "\n",
    "    question = meta_data_one_sample[\"question\"]\n",
    "    choices = meta_data_one_sample[\"choices\"]\n",
    "    mcToAsk = pg.question_generator(question, choices)\n",
    "    local_prompt_template = prompt_template + mcToAsk\n",
    "    output = model.predict_one(img_path,local_prompt_template,max_new_tokens=300)\n",
    "\n",
    "    # isSame  = compare_ans(output,base_ans)\n",
    "    cleaned_text = re.sub(r\"<.*>\", \"\", output)\n",
    "    last_row = cleaned_text.split('\\n')[-1]\n",
    "    match = re.findall(r\"\\{(.*?)\\}\", last_row)\n",
    "    if len(match) == 0:\n",
    "        with open(\"logs/eval_cot.log\",\"a\") as f:\n",
    "            f.write(\"No match found\")\n",
    "            f.write(output)\n",
    "            f.write(\"##############################################################################################################\")\n",
    "        continue\n",
    "    else:\n",
    "        model_ans = match[-1]\n",
    "        if model_ans not in ['A','B','C','D']:\n",
    "            with open(\"logs/eval_cot.log\",\"a\") as f:\n",
    "                f.write(\"Invalid answer\")\n",
    "                f.write(output)\n",
    "                f.write(\"##############################################################################################################\")\n",
    "\n",
    "            continue\n",
    "\n",
    "\n",
    "    if model_ans == base_ans:\n",
    "        isSame =  True\n",
    "    else:\n",
    "        isSame = False\n",
    "    if isSame:\n",
    "        # print(\"Correct\")\n",
    "        cnt += 1\n",
    "    else:\n",
    "        with open(\"logs/eval_cot.log\",\"a\") as f:\n",
    "            s = \"\"\"\n",
    "            Image: {}\n",
    "            Question: {}\n",
    "            Choices: {}\n",
    "            Base Answer: {}\n",
    "            Predicted Answer: {}\n",
    "            Ratinale: {}\n",
    "            direct_ans: {}\n",
    "            \"\"\".format(img_file, question, choices, base_ans, output, rationale, direct_ans)\n",
    "            f.write(s)\n",
    "            f.write(\"##############################################################################################################\")\n",
    "\n",
    "    if i % 100 == 0:\n",
    "         print('current accuracy', cnt/300)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aokvqa",
   "language": "python",
   "name": "aokvqa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
